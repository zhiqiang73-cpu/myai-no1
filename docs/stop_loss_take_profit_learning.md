# æ­¢ç›ˆæ­¢æŸçš„å¼ºåŒ–å­¦ä¹ è®¾è®¡

## æ ¸å¿ƒæ´å¯Ÿ

æ­¢ç›ˆæ­¢æŸçš„æœ¬è´¨æ˜¯ï¼š**åœ¨å“ªä¸ªä»·ä½ç¦»åœºèƒ½æœ€å¤§åŒ–æ”¶ç›Š**

è¿™ä¸æ”¯æ’‘é˜»åŠ›ä½ç›´æ¥ç›¸å…³ï¼š
- æ­¢æŸåº”è¯¥è®¾åœ¨æ”¯æ’‘ä½ä¸‹æ–¹ï¼ˆåšå¤šï¼‰æˆ–é˜»åŠ›ä½ä¸Šæ–¹ï¼ˆåšç©ºï¼‰
- æ­¢ç›ˆåº”è¯¥è®¾åœ¨ä¸‹ä¸€ä¸ªé˜»åŠ›ä½ï¼ˆåšå¤šï¼‰æˆ–æ”¯æ’‘ä½ï¼ˆåšç©ºï¼‰

**å…³é”®é—®é¢˜**ï¼šAIå¦‚ä½•å­¦ä¼šæ‰¾åˆ°æœ€ä¼˜çš„æ­¢ç›ˆæ­¢æŸä½ç½®ï¼Ÿ

---

## ä¸€ã€æ­¢ç›ˆæ­¢æŸå­¦ä¹ çš„ä¸‰ç§æ–¹æ¡ˆ

### æ–¹æ¡ˆAï¼šå›ºå®šè§„åˆ™ + å‚æ•°ä¼˜åŒ–ï¼ˆç®€å•ä½†æœ‰æ•ˆï¼‰

```
æ­¢æŸ = å…¥åœºä»· Â± ATR Ã— æ­¢æŸå€æ•°
æ­¢ç›ˆ = å…¥åœºä»· Â± ATR Ã— æ­¢ç›ˆå€æ•°

AIå­¦ä¹ çš„æ˜¯ï¼šæœ€ä¼˜çš„æ­¢æŸå€æ•°å’Œæ­¢ç›ˆå€æ•°
```

**ä¼˜ç‚¹**ï¼šç®€å•ï¼Œå®¹æ˜“å­¦ä¹ 
**ç¼ºç‚¹**ï¼šä¸è€ƒè™‘å¸‚åœºç»“æ„ï¼Œå¯èƒ½é”™è¿‡æ›´å¥½çš„ä½ç½®

### æ–¹æ¡ˆBï¼šåŸºäºæ”¯æ’‘é˜»åŠ›çš„åŠ¨æ€æ­¢ç›ˆæ­¢æŸï¼ˆæ¨èï¼‰â­

```
æ­¢æŸ = æœ€è¿‘çš„æ”¯æ’‘/é˜»åŠ›ä½ Â± ç¼“å†²è·ç¦»
æ­¢ç›ˆ = ä¸‹ä¸€ä¸ªé˜»åŠ›/æ”¯æ’‘ä½

AIå­¦ä¹ çš„æ˜¯ï¼š
1. å“ªäº›ä»·ä½æ˜¯æœ‰æ•ˆçš„æ”¯æ’‘é˜»åŠ›
2. ç¼“å†²è·ç¦»åº”è¯¥å¤šå¤§
3. æ˜¯å¦åº”è¯¥åˆ†æ‰¹æ­¢ç›ˆ
```

**ä¼˜ç‚¹**ï¼šç¬¦åˆå¸‚åœºé€»è¾‘ï¼Œæ­¢ç›ˆæ­¢æŸæœ‰ä¾æ®
**ç¼ºç‚¹**ï¼šéœ€è¦å…ˆå­¦ä¼šè¯†åˆ«æ”¯æ’‘é˜»åŠ›

### æ–¹æ¡ˆCï¼šå®Œå…¨ç”±AIå†³å®šï¼ˆæœ€çµæ´»ä½†æœ€éš¾ï¼‰

```
AIç›´æ¥è¾“å‡ºï¼šæ­¢æŸä»·æ ¼ã€æ­¢ç›ˆä»·æ ¼

åŠ¨ä½œç©ºé—´æ‰©å±•ä¸ºï¼š
[æ–¹å‘, ä»“ä½, æ­¢æŸä»·, æ­¢ç›ˆä»·]
```

**ä¼˜ç‚¹**ï¼šæœ€çµæ´»
**ç¼ºç‚¹**ï¼šæœç´¢ç©ºé—´å¤ªå¤§ï¼Œéš¾ä»¥æ”¶æ•›

---

## äºŒã€æ¨èæ–¹æ¡ˆï¼šåˆ†å±‚å­¦ä¹ 

æˆ‘å»ºè®®é‡‡ç”¨**åˆ†å±‚å­¦ä¹ **ï¼ŒæŠŠé—®é¢˜æ‹†è§£ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    åˆ†å±‚å­¦ä¹ æ¶æ„                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Layer 1: ä»·ä½å‘ç°å±‚ (Level Discovery)                           â”‚
â”‚  â”œâ”€â”€ è¾“å…¥: Kçº¿æ•°æ®ã€æˆäº¤é‡æ•°æ®                                    â”‚
â”‚  â”œâ”€â”€ è¾“å‡º: å€™é€‰æ”¯æ’‘é˜»åŠ›ä½åˆ—è¡¨                                     â”‚
â”‚  â”œâ”€â”€ æ–¹æ³•: æŠ€æœ¯åˆ†æ + ç»Ÿè®¡éªŒè¯                                    â”‚
â”‚  â””â”€â”€ å­¦ä¹ : å“ªäº›ä»·ä½è¢«å¸‚åœºå°Šé‡ï¼ˆä»·æ ¼åœ¨æ­¤åè½¬ï¼‰                      â”‚
â”‚                                                                 â”‚
â”‚  Layer 2: ä»·ä½è¯„åˆ†å±‚ (Level Scoring)                             â”‚
â”‚  â”œâ”€â”€ è¾“å…¥: å€™é€‰ä»·ä½ + å†å²äº¤æ˜“ç»“æœ                                â”‚
â”‚  â”œâ”€â”€ è¾“å‡º: æ¯ä¸ªä»·ä½çš„æœ‰æ•ˆæ€§å¾—åˆ†                                   â”‚
â”‚  â”œâ”€â”€ æ–¹æ³•: å¼ºåŒ–å­¦ä¹ æ›´æ–°å¾—åˆ†                                       â”‚
â”‚  â””â”€â”€ å­¦ä¹ : åœ¨æŸä»·ä½äº¤æ˜“çš„æˆåŠŸç‡å’Œç›ˆäºæ¯”                           â”‚
â”‚                                                                 â”‚
â”‚  Layer 3: æ­¢ç›ˆæ­¢æŸå†³ç­–å±‚ (SL/TP Decision)                        â”‚
â”‚  â”œâ”€â”€ è¾“å…¥: å…¥åœºä»· + è¯„åˆ†åçš„æ”¯æ’‘é˜»åŠ›ä½                            â”‚
â”‚  â”œâ”€â”€ è¾“å‡º: æ­¢æŸä»·ã€æ­¢ç›ˆä»·ï¼ˆå¯èƒ½å¤šä¸ªç›®æ ‡ï¼‰                         â”‚
â”‚  â”œâ”€â”€ æ–¹æ³•: åŸºäºè§„åˆ™ + AIå¾®è°ƒ                                     â”‚
â”‚  â””â”€â”€ å­¦ä¹ : æœ€ä¼˜çš„ç¼“å†²è·ç¦»ã€æ˜¯å¦åˆ†æ‰¹æ­¢ç›ˆ                           â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ä¸‰ã€Layer 1: ä»·ä½å‘ç° - è¯¦ç»†å®ç°

### 3.1 ä»·ä½å€™é€‰ç”Ÿæˆ

```python
class LevelDiscovery:
    """ä»·ä½å‘ç°å™¨"""
    
    def __init__(self):
        self.candidate_levels = []  # å€™é€‰ä»·ä½
        self.confirmed_levels = []  # å·²ç¡®è®¤çš„æœ‰æ•ˆä»·ä½
    
    def discover_levels(self, klines_15m, klines_8h, current_price):
        """
        å‘ç°å€™é€‰æ”¯æ’‘é˜»åŠ›ä½
        """
        candidates = []
        
        # 1. Pivot Points
        pivots = self._find_pivots(klines_15m)
        candidates.extend(pivots)
        
        # 2. Volume Nodes
        volume_levels = self._find_volume_nodes(klines_8h)
        candidates.extend(volume_levels)
        
        # 3. Round Numbers
        round_levels = self._find_round_numbers(current_price)
        candidates.extend(round_levels)
        
        # 4. åˆå¹¶ç›¸è¿‘ä»·ä½
        merged = self._merge_nearby_levels(candidates)
        
        # 5. åˆå§‹åŒ–å¾—åˆ†
        for level in merged:
            level["score"] = level.get("initial_score", 50)
            level["touch_count"] = 0
            level["success_count"] = 0
            level["total_pnl"] = 0
        
        return merged
```

### 3.2 ä»·ä½çš„"è§¦åŠ"æ£€æµ‹

```python
def detect_level_touch(self, price_history, level, threshold_percent=0.3):
    """
    æ£€æµ‹ä»·æ ¼æ˜¯å¦è§¦åŠæŸä¸ªä»·ä½
    
    è§¦åŠçš„å®šä¹‰ï¼š
    1. ä»·æ ¼æ¥è¿‘è¯¥ä»·ä½ï¼ˆè·ç¦» < thresholdï¼‰
    2. ç„¶åå‘ç”Ÿåè½¬ï¼ˆåå‘ç§»åŠ¨è¶…è¿‡thresholdï¼‰
    """
    level_price = level["price"]
    touches = []
    
    for i in range(1, len(price_history) - 1):
        current = price_history[i]
        prev = price_history[i - 1]
        next_price = price_history[i + 1]
        
        # è®¡ç®—è·ç¦»
        distance_percent = abs(current - level_price) / level_price * 100
        
        if distance_percent < threshold_percent:
            # ä»·æ ¼æ¥è¿‘è¯¥ä»·ä½ï¼Œæ£€æŸ¥æ˜¯å¦åè½¬
            came_from = "above" if prev > current else "below"
            went_to = "above" if next_price > current else "below"
            
            if came_from != went_to:
                # å‘ç”Ÿåè½¬ï¼
                touches.append({
                    "index": i,
                    "price": current,
                    "direction": came_from,
                    "bounced": True
                })
            else:
                # ç©¿è¶Šäº†è¯¥ä»·ä½
                touches.append({
                    "index": i,
                    "price": current,
                    "direction": came_from,
                    "bounced": False,
                    "broke_through": True
                })
    
    return touches
```

---

## å››ã€Layer 2: ä»·ä½è¯„åˆ† - å¼ºåŒ–å­¦ä¹ æ ¸å¿ƒ

### 4.1 è¯„åˆ†æ›´æ–°æœºåˆ¶

```python
class LevelScoring:
    """
    ä»·ä½è¯„åˆ†ç³»ç»Ÿ
    
    æ ¸å¿ƒæ€æƒ³ï¼š
    - æ¯æ¬¡åœ¨æŸä»·ä½é™„è¿‘äº¤æ˜“ï¼Œè®°å½•ç»“æœ
    - æˆåŠŸçš„äº¤æ˜“æå‡è¯¥ä»·ä½å¾—åˆ†
    - å¤±è´¥çš„äº¤æ˜“é™ä½è¯¥ä»·ä½å¾—åˆ†
    - å¾—åˆ†é«˜çš„ä»·ä½æ›´å¯èƒ½è¢«ç”¨ä½œæ­¢ç›ˆæ­¢æŸ
    """
    
    def __init__(self, learning_rate=0.1):
        self.lr = learning_rate
        self.levels = {}  # price -> LevelStats
    
    def update_level_score(self, level_price, trade_result):
        """
        æ ¹æ®äº¤æ˜“ç»“æœæ›´æ–°ä»·ä½å¾—åˆ†
        
        trade_result = {
            "entry_price": 92000,
            "exit_price": 92500,
            "direction": "LONG",
            "pnl_percent": 0.54,
            "used_as": "SUPPORT",  # è¿™ä¸ªä»·ä½è¢«ç”¨ä½œä»€ä¹ˆ
            "outcome": "BOUNCE"    # BOUNCE(åå¼¹æˆåŠŸ) / BREAK(çªç ´å¤±è´¥)
        }
        """
        if level_price not in self.levels:
            self.levels[level_price] = {
                "score": 50,
                "touch_count": 0,
                "bounce_count": 0,
                "break_count": 0,
                "total_pnl": 0,
                "trades": []
            }
        
        stats = self.levels[level_price]
        stats["touch_count"] += 1
        stats["trades"].append(trade_result)
        
        if trade_result["outcome"] == "BOUNCE":
            # ä»·ä½æœ‰æ•ˆï¼Œä»·æ ¼åœ¨æ­¤åå¼¹
            stats["bounce_count"] += 1
            
            # å¾—åˆ†æ›´æ–°ï¼šæˆåŠŸåå¼¹ + ç›ˆåˆ© = å¤§å¹…åŠ åˆ†
            if trade_result["pnl_percent"] > 0:
                score_delta = self.lr * (10 + trade_result["pnl_percent"] * 5)
            else:
                # åå¼¹äº†ä½†è¿˜æ˜¯äºé’±ï¼ˆå¯èƒ½å…¥åœºæ—¶æœºä¸å¯¹ï¼‰
                score_delta = self.lr * 2
            
            stats["score"] = min(100, stats["score"] + score_delta)
            
        elif trade_result["outcome"] == "BREAK":
            # ä»·ä½å¤±æ•ˆï¼Œä»·æ ¼çªç ´äº†
            stats["break_count"] += 1
            
            # å¾—åˆ†æ›´æ–°ï¼šçªç ´ = å‡åˆ†
            score_delta = self.lr * (5 + abs(trade_result["pnl_percent"]) * 3)
            stats["score"] = max(0, stats["score"] - score_delta)
        
        stats["total_pnl"] += trade_result["pnl_percent"]
        
        # è®¡ç®—æˆåŠŸç‡
        if stats["touch_count"] > 0:
            stats["success_rate"] = stats["bounce_count"] / stats["touch_count"]
        
        return stats
    
    def get_best_levels(self, current_price, direction, top_n=5):
        """
        è·å–æœ€ä½³çš„æ”¯æ’‘é˜»åŠ›ä½ç”¨äºæ­¢ç›ˆæ­¢æŸ
        
        direction: "LONG" or "SHORT"
        """
        support_levels = []
        resistance_levels = []
        
        for price, stats in self.levels.items():
            if stats["score"] < 30:  # è¿‡æ»¤ä½åˆ†ä»·ä½
                continue
            if stats["touch_count"] < 2:  # è‡³å°‘è¢«éªŒè¯è¿‡2æ¬¡
                continue
            
            level_info = {
                "price": price,
                "score": stats["score"],
                "success_rate": stats.get("success_rate", 0),
                "touch_count": stats["touch_count"]
            }
            
            if price < current_price:
                support_levels.append(level_info)
            else:
                resistance_levels.append(level_info)
        
        # æŒ‰å¾—åˆ†æ’åº
        support_levels.sort(key=lambda x: x["score"], reverse=True)
        resistance_levels.sort(key=lambda x: x["score"], reverse=True)
        
        if direction == "LONG":
            return {
                "stop_loss_candidates": support_levels[:top_n],
                "take_profit_candidates": resistance_levels[:top_n]
            }
        else:
            return {
                "stop_loss_candidates": resistance_levels[:top_n],
                "take_profit_candidates": support_levels[:top_n]
            }
```

### 4.2 ä»·ä½å¾—åˆ†çš„è¡°å‡æœºåˆ¶

```python
def decay_old_levels(self, current_time, decay_rate=0.99):
    """
    é•¿æœŸæœªè¢«è§¦åŠçš„ä»·ä½ï¼Œå¾—åˆ†é€æ¸è¡°å‡
    
    åŸå› ï¼šå¸‚åœºç»“æ„ä¼šå˜åŒ–ï¼Œæ—§çš„æ”¯æ’‘é˜»åŠ›å¯èƒ½å¤±æ•ˆ
    """
    for price, stats in self.levels.items():
        if stats["trades"]:
            last_trade_time = stats["trades"][-1].get("time")
            days_since_last = (current_time - last_trade_time).days
            
            if days_since_last > 7:
                # è¶…è¿‡7å¤©æœªè§¦åŠï¼Œå¼€å§‹è¡°å‡
                decay_factor = decay_rate ** (days_since_last - 7)
                stats["score"] *= decay_factor
```

---

## äº”ã€Layer 3: æ­¢ç›ˆæ­¢æŸå†³ç­–

### 5.1 åŸºäºè¯„åˆ†ä»·ä½çš„æ­¢ç›ˆæ­¢æŸ

```python
class StopLossTakeProfitDecision:
    """
    æ­¢ç›ˆæ­¢æŸå†³ç­–å™¨
    """
    
    def __init__(self, level_scoring: LevelScoring):
        self.scoring = level_scoring
        
        # å¯å­¦ä¹ çš„å‚æ•°
        self.params = {
            "sl_buffer_atr_mult": 0.5,   # æ­¢æŸç¼“å†² = ATR Ã— è¿™ä¸ªå€¼
            "min_risk_reward": 1.5,       # æœ€å°é£é™©æ”¶ç›Šæ¯”
            "partial_tp_enabled": True,   # æ˜¯å¦åˆ†æ‰¹æ­¢ç›ˆ
            "partial_tp_ratio": 0.5,      # ç¬¬ä¸€ç›®æ ‡æ­¢ç›ˆæ¯”ä¾‹
        }
    
    def calculate_sl_tp(self, entry_price, direction, atr, current_price):
        """
        è®¡ç®—æ­¢æŸæ­¢ç›ˆä½ç½®
        
        é€»è¾‘ï¼š
        1. æ‰¾åˆ°æœ€è¿‘çš„é«˜åˆ†æ”¯æ’‘/é˜»åŠ›ä½
        2. æ­¢æŸè®¾åœ¨è¯¥ä»·ä½å¤–ä¾§ + ç¼“å†²
        3. æ­¢ç›ˆè®¾åœ¨ä¸‹ä¸€ä¸ªé«˜åˆ†é˜»åŠ›/æ”¯æ’‘ä½
        4. æ£€æŸ¥é£é™©æ”¶ç›Šæ¯”ï¼Œä¸æ»¡è¶³åˆ™æ”¾å¼ƒäº¤æ˜“
        """
        
        # è·å–å€™é€‰ä»·ä½
        levels = self.scoring.get_best_levels(current_price, direction)
        
        if direction == "LONG":
            # åšå¤šï¼šæ­¢æŸåœ¨æ”¯æ’‘ä¸‹æ–¹ï¼Œæ­¢ç›ˆåœ¨é˜»åŠ›
            sl_candidates = levels["stop_loss_candidates"]
            tp_candidates = levels["take_profit_candidates"]
            
            if not sl_candidates:
                # æ²¡æœ‰å·²çŸ¥æ”¯æ’‘ï¼Œä½¿ç”¨ATR
                stop_loss = entry_price - atr * 1.5
            else:
                # ä½¿ç”¨æœ€è¿‘çš„é«˜åˆ†æ”¯æ’‘
                nearest_support = min(sl_candidates, key=lambda x: entry_price - x["price"])
                buffer = atr * self.params["sl_buffer_atr_mult"]
                stop_loss = nearest_support["price"] - buffer
            
            if not tp_candidates:
                # æ²¡æœ‰å·²çŸ¥é˜»åŠ›ï¼Œä½¿ç”¨é£é™©æ”¶ç›Šæ¯”è®¡ç®—
                risk = entry_price - stop_loss
                take_profit = entry_price + risk * self.params["min_risk_reward"]
            else:
                # ä½¿ç”¨æœ€è¿‘çš„é«˜åˆ†é˜»åŠ›
                nearest_resistance = min(tp_candidates, key=lambda x: x["price"] - entry_price)
                take_profit = nearest_resistance["price"]
        
        else:  # SHORT
            sl_candidates = levels["stop_loss_candidates"]
            tp_candidates = levels["take_profit_candidates"]
            
            if not sl_candidates:
                stop_loss = entry_price + atr * 1.5
            else:
                nearest_resistance = min(sl_candidates, key=lambda x: x["price"] - entry_price)
                buffer = atr * self.params["sl_buffer_atr_mult"]
                stop_loss = nearest_resistance["price"] + buffer
            
            if not tp_candidates:
                risk = stop_loss - entry_price
                take_profit = entry_price - risk * self.params["min_risk_reward"]
            else:
                nearest_support = min(tp_candidates, key=lambda x: entry_price - x["price"])
                take_profit = nearest_support["price"]
        
        # è®¡ç®—é£é™©æ”¶ç›Šæ¯”
        risk = abs(entry_price - stop_loss)
        reward = abs(take_profit - entry_price)
        risk_reward_ratio = reward / risk if risk > 0 else 0
        
        return {
            "stop_loss": round(stop_loss, 2),
            "take_profit": round(take_profit, 2),
            "risk": risk,
            "reward": reward,
            "risk_reward_ratio": round(risk_reward_ratio, 2),
            "is_valid": risk_reward_ratio >= self.params["min_risk_reward"],
            "sl_based_on": "SUPPORT_LEVEL" if sl_candidates else "ATR",
            "tp_based_on": "RESISTANCE_LEVEL" if tp_candidates else "RISK_REWARD",
        }
```

### 5.2 å‚æ•°çš„å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–

```python
class SLTPParameterLearner:
    """
    å­¦ä¹ æœ€ä¼˜çš„æ­¢ç›ˆæ­¢æŸå‚æ•°
    
    ä½¿ç”¨ç®€å•çš„è¿›åŒ–ç­–ç•¥ï¼š
    1. ç»´æŠ¤ä¸€ç»„å‚æ•°
    2. æ¯Nç¬”äº¤æ˜“è¯„ä¼°æ•ˆæœ
    3. å¥½çš„å‚æ•°ä¿ç•™ï¼Œå·®çš„å‚æ•°å˜å¼‚
    """
    
    def __init__(self):
        # å‚æ•°æœç´¢ç©ºé—´
        self.param_space = {
            "sl_buffer_atr_mult": (0.2, 1.0),   # èŒƒå›´
            "min_risk_reward": (1.0, 3.0),
            "partial_tp_ratio": (0.3, 0.7),
        }
        
        # å½“å‰æœ€ä¼˜å‚æ•°
        self.best_params = {
            "sl_buffer_atr_mult": 0.5,
            "min_risk_reward": 1.5,
            "partial_tp_ratio": 0.5,
        }
        self.best_score = 0
        
        # å‚æ•°å†å²
        self.param_history = []
    
    def evaluate_params(self, trades):
        """
        è¯„ä¼°å½“å‰å‚æ•°çš„æ•ˆæœ
        """
        if len(trades) < 20:
            return None
        
        # è®¡ç®—å…³é”®æŒ‡æ ‡
        wins = sum(1 for t in trades if t["pnl"] > 0)
        win_rate = wins / len(trades)
        
        total_profit = sum(t["pnl"] for t in trades if t["pnl"] > 0)
        total_loss = abs(sum(t["pnl"] for t in trades if t["pnl"] < 0))
        profit_factor = total_profit / total_loss if total_loss > 0 else float('inf')
        
        # ç»¼åˆå¾—åˆ†
        score = win_rate * 0.3 + min(profit_factor, 3) / 3 * 0.7
        
        return {
            "win_rate": win_rate,
            "profit_factor": profit_factor,
            "score": score,
            "trades_count": len(trades)
        }
    
    def mutate_params(self, mutation_rate=0.1):
        """
        å˜å¼‚å‚æ•°ï¼Œæ¢ç´¢æ–°çš„ç»„åˆ
        """
        import random
        
        new_params = {}
        for key, (min_val, max_val) in self.param_space.items():
            current = self.best_params[key]
            
            # é«˜æ–¯å˜å¼‚
            mutation = random.gauss(0, (max_val - min_val) * mutation_rate)
            new_value = current + mutation
            
            # é™åˆ¶åœ¨èŒƒå›´å†…
            new_value = max(min_val, min(max_val, new_value))
            new_params[key] = round(new_value, 3)
        
        return new_params
    
    def update(self, trades, current_params):
        """
        æ ¹æ®äº¤æ˜“ç»“æœæ›´æ–°å‚æ•°
        """
        eval_result = self.evaluate_params(trades)
        if eval_result is None:
            return
        
        self.param_history.append({
            "params": current_params.copy(),
            "result": eval_result
        })
        
        if eval_result["score"] > self.best_score:
            self.best_score = eval_result["score"]
            self.best_params = current_params.copy()
            print(f"ğŸ¯ å‘ç°æ›´ä¼˜å‚æ•°! Score: {eval_result['score']:.3f}")
            print(f"   Win Rate: {eval_result['win_rate']:.1%}")
            print(f"   Profit Factor: {eval_result['profit_factor']:.2f}")
            print(f"   Params: {self.best_params}")
```
